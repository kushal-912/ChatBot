{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:56:07.327453Z","iopub.execute_input":"2025-05-05T04:56:07.327873Z","iopub.status.idle":"2025-05-05T04:56:11.333634Z","shell.execute_reply.started":"2025-05-05T04:56:07.327840Z","shell.execute_reply":"2025-05-05T04:56:11.332290Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import os\nimport random\nimport string\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nimport numpy as np\nfrom torch.utils.tensorboard import SummaryWriter\nimport uuid\n\n# -----------------------\n# Reproducibility\n# -----------------------\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# -----------------------\n# Command-Line Arguments (with Jupyter compatibility)\n# -----------------------\ndef is_jupyter():\n    try:\n        get_ipython()\n        return True\n    except NameError:\n        return False\n\nif is_jupyter():\n    args = {\n        'model_dir': '/content/drive/MyDrive/models',\n        'checkpoint_dir': '/content/drive/MyDrive/checkpoints',\n        'log_dir': 'logs',\n        'epochs': 10,\n        'batch_size': 64\n    }\n    args = argparse.Namespace(**args)\nelse:\n    parser = argparse.ArgumentParser(description=\"Seq2Seq Chatbot Training\")\n    parser.add_argument('--model-dir', default='models', help='Directory to save models')\n    parser.add_argument('--checkpoint-dir', default='checkpoints', help='Directory to save checkpoints')\n    parser.add_argument('--log-dir', default='logs', help='Directory for TensorBoard logs')\n    parser.add_argument('--epochs', type=int, default=10, help='Number of training epochs')\n    parser.add_argument('--batch-size', type=int, default=64, help='Batch size')\n    args = parser.parse_args()\n\n# -----------------------\n# Constants & Hyperparameters\n# -----------------------\nSOS_TOKEN = \"<sos>\"\nEOS_TOKEN = \"<eos>\"\nPAD_TOKEN = \"<pad>\"\nUNK_TOKEN = \"<unk>\"\nVOCAB = None\nVOCAB_SIZE = None\nchar2idx = None\nidx2char = None\n\nEMBEDDING_DIM = 256\nHIDDEN_SIZE = 768\nNUM_LAYERS = 3\nDROPOUT = 0.3\nBATCH_SIZE = args.batch_size\nNUM_EPOCHS = args.epochs\nMAX_SEQ_LEN = 100\nINITIAL_TEACHER_FORCING = 0.7\nMIN_TEACHER_FORCING = 0.3\nLEARNING_RATE = 5e-4\nBEAM_WIDTH = 5\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nwriter = SummaryWriter(log_dir=args.log_dir)\n\n# -----------------------\n# Teacher Forcing Scheduler\n# -----------------------\ndef current_tf(epoch):\n    return max(MIN_TEACHER_FORCING,\n               INITIAL_TEACHER_FORCING - ((epoch - 1) * (INITIAL_TEACHER_FORCING - MIN_TEACHER_FORCING) / NUM_EPOCHS))\n\n# -----------------------\n# Dataset: DailyDialog pairs\n# -----------------------\nclass ChatbotDataset(Dataset):\n    def __init__(self,split='train', max_seq_len=MAX_SEQ_LEN, vocab=None):\n        self.max_seq_len = max_seq_len\n        raw = load_dataset('daily_dialog', split=split)\n        pairs = []\n        chars = set()\n\n        for dialog in raw['dialog']:\n            for i in range(len(dialog) - 1):\n                src, tgt = dialog[i].lower(), dialog[i+1].lower()\n                if len(src) <= max_seq_len and len(tgt) <= max_seq_len:\n                    pairs.append((src, tgt))\n                    chars.update(src + tgt)\n\n        global VOCAB, VOCAB_SIZE, char2idx, idx2char\n        if vocab is None:\n            chars = sorted(list(chars))[:1000]\n            VOCAB = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + chars\n            VOCAB_SIZE = len(VOCAB)\n            char2idx = {c: i for i, c in enumerate(VOCAB)}\n            idx2char = {i: c for i, c in enumerate(VOCAB)}\n        else:\n            VOCAB = vocab\n            VOCAB_SIZE = len(VOCAB)\n            char2idx = {c: i for i, c in enumerate(VOCAB)}\n            idx2char = {i: c for i, c in enumerate(VOCAB)}\n\n        augmented_pairs = []\n        chars_list = list(chars)\n        for src, tgt in pairs:\n            augmented_pairs.append((src, tgt))\n            if random.random() < 0.1:\n                src_aug = ''.join(c if random.random() > 0.05 else random.choice(chars_list) for c in src)\n                tgt_aug = ''.join(c if random.random() > 0.05 else random.choice(chars_list) for c in tgt)\n                augmented_pairs.append((src_aug, tgt_aug))\n\n        random.shuffle(augmented_pairs)\n        self.pairs = augmented_pairs\n        print(f\"Loaded {len(self.pairs)} pairs from DailyDialog {split}, VOCAB_SIZE={VOCAB_SIZE}\")\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        src, tgt = self.pairs[idx]\n        src_ids = [char2idx[SOS_TOKEN]] + [char2idx.get(ch, char2idx[UNK_TOKEN]) for ch in src]\n        tgt_ids = [char2idx.get(ch, char2idx[UNK_TOKEN]) for ch in tgt] + [char2idx[EOS_TOKEN]]\n        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n\ndef collate_fn(batch):\n    srcs, tgts = zip(*batch)\n    lens_src = [len(s) for s in srcs]\n    lens_tgt = [len(t) for t in tgts]\n    src_pad = nn.utils.rnn.pad_sequence(srcs, batch_first=True, padding_value=char2idx[PAD_TOKEN])\n    tgt_pad = nn.utils.rnn.pad_sequence(tgts, batch_first=True, padding_value=char2idx[PAD_TOKEN])\n    return src_pad, torch.tensor(lens_src), tgt_pad, torch.tensor(lens_tgt)\n\ntrain_ds = ChatbotDataset(split='train')\nvocab = VOCAB\nval_ds = ChatbotDataset(split='validation', vocab=vocab)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\n# -----------------------\n# Model Definitions\n# -----------------------\nclass Encoder(nn.Module):\n    def __init__(self, vs, ed, hs, nl, do):\n        super().__init__()\n        self.embedding = nn.Embedding(vs, ed)\n        lstm_dropout = do if nl > 1 else 0\n        self.lstm = nn.LSTM(ed, hs, nl, batch_first=True, dropout=lstm_dropout, bidirectional=True)\n        self.norm = nn.LayerNorm(hs * 2)\n\n    def forward(self, x, lengths):\n        emb = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n        out_packed, (h, c) = self.lstm(packed)\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)\n        h = h.view(self.lstm.num_layers, 2, -1, self.lstm.hidden_size).sum(dim=1)\n        c = c.view(self.lstm.num_layers, 2, -1, self.lstm.hidden_size).sum(dim=1)\n        outputs = self.norm(outputs)\n        return outputs, h, c\n\nclass Decoder(nn.Module):\n    def __init__(self, vs, ed, hs, nl, do):\n        super().__init__()\n        self.embedding = nn.Embedding(vs, ed)\n        lstm_dropout = do if nl > 1 else 0\n        self.lstm = nn.LSTM(ed, hs, nl, batch_first=True, dropout=lstm_dropout)\n        self.enc_proj = nn.Linear(hs * 2, hs)\n        self.attention = nn.MultiheadAttention(hs, num_heads=8, dropout=do)\n        self.norm1 = nn.LayerNorm(hs)\n        self.norm2 = nn.LayerNorm(hs)\n        self.fc = nn.Linear(hs, vs)\n        self.dropout = nn.Dropout(do)\n\n    def forward(self, token, h, c, enc_out):\n        emb = self.embedding(token.unsqueeze(1))  # (batch_size, 1, EMBEDDING_DIM)\n        lstm_out, (h, c) = self.lstm(emb, (h, c))  # (batch_size, 1, HIDDEN_SIZE)\n        enc_out_proj = self.enc_proj(enc_out)  # (batch_size, seq_len, HIDDEN_SIZE)\n        attn_out, _ = self.attention(\n            lstm_out.transpose(0, 1),  # (1, batch_size, HIDDEN_SIZE)\n            enc_out_proj.transpose(0, 1),  # (seq_len, batch_size, HIDDEN_SIZE)\n            enc_out_proj.transpose(0, 1)\n        )  # (1, batch_size, HIDDEN_SIZE)\n        attn_out = attn_out.transpose(0, 1)  # (batch_size, 1, HIDDEN_SIZE)\n        out = self.norm1(lstm_out + attn_out)  # (batch_size, 1, HIDDEN_SIZE)\n        out = self.norm2(self.dropout(torch.relu(out)))  # (batch_size, 1, HIDDEN_SIZE)\n        out = out.view(-1, out.size(-1))  # (batch_size, HIDDEN_SIZE)\n        return self.fc(out), h, c\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, enc, dec):\n        super().__init__()\n        self.encoder = enc\n        self.decoder = dec\n\n    def forward(self, src, lengths, tgt, tf_ratio):\n        batch_size, tgt_len = tgt.size()\n        outputs = torch.zeros(batch_size, tgt_len, VOCAB_SIZE, device=src.device)\n        enc_out, h, c = self.encoder(src, lengths)\n        inp = torch.full((batch_size,), char2idx[SOS_TOKEN], dtype=torch.long, device=src.device)\n        for t in range(tgt_len):\n            out_step, h, c = self.decoder(inp, h, c, enc_out)\n            outputs[:, t, :] = out_step\n            teacher_force = random.random() < tf_ratio\n            top1 = out_step.argmax(1)\n            inp = tgt[:, t] if teacher_force else top1\n        return outputs\n\n# -----------------------\n# Initialize Everything\n# -----------------------\nencoder = Encoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(device)\ndecoder = Decoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(device)\nmodel = Seq2Seq(encoder, decoder).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1, ignore_index=char2idx[PAD_TOKEN])\n\n# -----------------------\n# Batch Beam Search Decode\n# -----------------------\ndef batch_beam_search_decode(model, enc_out, h, c, beam_width=BEAM_WIDTH, max_len=100):\n    batch_size = enc_out.size(0)\n    beams = [[([char2idx[SOS_TOKEN]], 0.0, h[:, i:i+1], c[:, i:i+1])] for i in range(batch_size)]\n    completed = [[] for _ in range(batch_size)]\n\n    for _ in range(max_len):\n        new_beams = [[] for _ in range(batch_size)]\n        for b in range(batch_size):\n            if len(completed[b]) >= beam_width:\n                continue\n            for seq, score, h1, c1 in beams[b]:\n                inp = torch.tensor([seq[-1]], device=h1.device, dtype=torch.long)\n                out, h2, c2 = model.decoder(inp, h1, c1, enc_out[b:b+1])\n                logp = torch.log_softmax(out, dim=1)  # Shape: (1, VOCAB_SIZE)\n                topk = torch.topk(logp, beam_width, dim=1)\n                for idx, lp in zip(topk.indices[0], topk.values[0]):\n                    new_seq = seq + [idx.item()]\n                    lp_factor = ((5 + len(new_seq)) / 6) ** 0.7\n                    new_score = (score + lp.item()) / lp_factor\n                    if idx.item() == char2idx[EOS_TOKEN]:\n                        completed[b].append((new_seq, new_score))\n                    else:\n                        new_beams[b].append((new_seq, new_score, h2, c2))\n            beams[b] = sorted(new_beams[b], key=lambda x: x[1], reverse=True)[:beam_width]\n        if all(len(c) >= beam_width for c in completed):\n            break\n\n    outputs = []\n    for b in range(batch_size):\n        best = max(completed[b] + beams[b], key=lambda x: x[1]) if completed[b] or beams[b] else ([], 0.0)\n        seq = ''.join(idx2char[i] for i in best[0] if i not in (char2idx[SOS_TOKEN], char2idx[EOS_TOKEN]))\n        outputs.append(seq)\n    return outputs\n\n# -----------------------\n# Training & Validation\n# -----------------------\ndef train_epoch(epoch):\n    model.train()\n    total_loss = 0\n    tf = current_tf(epoch)\n    for src, slen, tgt, tlen in tqdm(train_loader, desc=f\"Train {epoch}\"):\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        out = model(src, slen, tgt, tf)\n        loss = criterion(out.view(-1, VOCAB_SIZE), tgt.view(-1))\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        total_loss += loss.item()\n    avg_loss = total_loss / len(train_loader)\n    writer.add_scalar('Loss/Train', avg_loss, epoch)\n    writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n    return avg_loss\n\ndef validate():\n    model.eval()\n    total_loss = 0\n    references = []\n    hypotheses = []\n    with torch.no_grad():\n        for src, slen, tgt, tlen in tqdm(val_loader, desc=\"Val\"):\n            src, tgt = src.to(device), tgt.to(device)\n            out = model(src, slen, tgt, tf_ratio=0)\n            loss = criterion(out.view(-1, VOCAB_SIZE), tgt.view(-1))\n            total_loss += loss.item()\n\n            enc_out, h, c = model.encoder(src, slen)\n            preds = batch_beam_search_decode(model, enc_out, h, c)\n            for pred, ref in zip(preds, tgt):\n                ref_chars = [idx2char[idx.item()] for idx in ref if idx not in (char2idx[PAD_TOKEN], char2idx[EOS_TOKEN])]\n                references.append([ref_chars])\n                hypotheses.append(list(pred))\n\n    avg_loss = total_loss / len(val_loader)\n    bleu = corpus_bleu(references, hypotheses, smoothing_function=SmoothingFunction().method1)\n    perplexity = torch.exp(torch.tensor(avg_loss))\n    writer.add_scalar('Loss/Val', avg_loss, epoch)\n    writer.add_scalar('BLEU/Val', bleu, epoch)\n    writer.add_scalar('Perplexity/Val', perplexity, epoch)\n    return avg_loss, bleu, perplexity\n\ndef evaluate_sentence(sent):\n    model.eval()\n    with torch.no_grad():\n        seq = [char2idx[SOS_TOKEN]] + [char2idx.get(ch, char2idx[UNK_TOKEN]) for ch in sent.lower()]\n        tensor = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(device)\n        length = torch.tensor([len(seq)])\n        enc_out, h, c = model.encoder(tensor, length)\n        return batch_beam_search_decode(model, enc_out, h, c)[0]\n\n# -----------------------\n# Main Loop\n# -----------------------\nif __name__ == \"__main__\":\n    os.makedirs(args.model_dir, exist_ok=True)\n    os.makedirs(args.checkpoint_dir, exist_ok=True)\n\n    CHECKPOINT_PATH = os.path.join(args.checkpoint_dir, \"seq2seq_epoch_{epoch}.pth\")\n    MODEL_PATH = os.path.join(args.model_dir, \"seq2seq_daily_dialog.pth\")\n\n    RESUME_FROM = 0\n\n    def save_checkpoint(epoch, model, optimizer, scheduler):\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict()\n        }, CHECKPOINT_PATH.format(epoch=epoch))\n\n    def load_checkpoint(path):\n        checkpoint = torch.load(path, map_location=device)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        return checkpoint['epoch']\n\n    start_epoch = 5\n    if RESUME_FROM:\n        print(f\"Resuming training from epoch {RESUME_FROM}...\")\n        resume_path = CHECKPOINT_PATH.format(epoch=RESUME_FROM)\n        start_epoch = load_checkpoint(resume_path) + 1\n\n    for epoch in range(start_epoch, NUM_EPOCHS + 1):\n        tr_loss = train_epoch(epoch)\n        val_loss, val_bleu, val_perplexity = validate()\n        scheduler.step(val_loss)\n        print(f\"Epoch {epoch} | Train Loss: {tr_loss:.4f} | Val Loss: {val_loss:.4f} | BLEU: {val_bleu:.4f} | Perplexity: {val_perplexity:.2f}\")\n\n        if epoch % 2 == 0:\n            save_checkpoint(epoch, model, optimizer, scheduler)\n\n        inp = random.choice(train_ds.pairs)[0]\n        out = evaluate_sentence(inp)\n        print(f\"Sample In: {inp}\\nOut: {out}\")\n\n    torch.save(model.state_dict(), MODEL_PATH)\n    print(f\"Final model saved to {MODEL_PATH}\")\n    writer.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:57:51.300879Z","iopub.execute_input":"2025-05-05T04:57:51.301214Z","iopub.status.idle":"2025-05-05T04:57:51.456532Z","shell.execute_reply.started":"2025-05-05T04:57:51.301181Z","shell.execute_reply":"2025-05-05T04:57:51.454992Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"!mkdir checkpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:58:00.494908Z","iopub.execute_input":"2025-05-05T04:58:00.495411Z","iopub.status.idle":"2025-05-05T04:58:00.621399Z","shell.execute_reply.started":"2025-05-05T04:58:00.495226Z","shell.execute_reply":"2025-05-05T04:58:00.619979Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}